{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2109d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "from os.path import join\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from cnrg.VRG import VRG as VRG\n",
    "from cnrg.LightMultiGraph import LightMultiGraph as LightMultiGraph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42cc78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src')\n",
    "from data import load_data\n",
    "from data_old import read_data\n",
    "from bookkeeping import convert_LMG, decompose\n",
    "from update_grammar import update_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957611f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('change 10 -> 15 and fix that error on \"graphs = graphs[0:10]\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7306dd",
   "metadata": {},
   "source": [
    "# independent sequential experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4122a38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████|[00:00<00:00]\n",
      "WARNING:root:graph: , mu: 4, type: mu_level_dl clustering: leiden rules: 112(112) mdl: 16_515.8 bits generated in 0.237 secs\n",
      "\n",
      "joint changes: 1:   0%|          | 0/71 [00:00<?, ?it/s]\n",
      "  0%|                                   |[00:00<?]\u001b[A\n",
      "100%|███████████████████████████████|[00:00<00:00]\u001b[A\n",
      "WARNING:root:graph: , mu: 4, type: mu_level_dl clustering: leiden rules: 102(102) mdl: 11_796.4 bits generated in 0.113 secs\n",
      "\n",
      "joint changes: 1:   1%|▏         | 1/71 [00:01<01:51,  1.60s/it]\n",
      "100%|███████████████████████████████|[00:00<00:00]\u001b[A\n",
      "WARNING:root:graph: , mu: 4, type: mu_level_dl clustering: leiden rules: 2(2) mdl: 158.808 bits generated in 0.002 secs\n",
      "\n",
      "joint changes: 1: 100%|██████████| 71/71 [00:01<00:00, 43.07it/s]\n",
      "additions: 1: 100%|██████████| 459/459 [00:03<00:00, 131.66it/s]\n",
      "additions: 2: 100%|██████████| 5/5 [00:00<00:00, 245.40it/s]\n",
      "additions: 1:  18%|█▊        | 147/830 [00:01<00:04, 137.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m base_grammar \u001b[38;5;241m=\u001b[39m decompose(home_graph, mu\u001b[38;5;241m=\u001b[39mmu)\n\u001b[1;32m     30\u001b[0m joint_grammar \u001b[38;5;241m=\u001b[39m update_grammar(base_grammar, home_graph, away_graph, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjoint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m indep_grammar \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_grammar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_grammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhome_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maway_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindependent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m base_grammars[lookback] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [base_grammar]\n\u001b[1;32m     34\u001b[0m joint_grammars[lookback] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [joint_grammar]\n",
      "File \u001b[0;32m~/repos/temporal_VRG/notebooks/../src/update_grammar.py:97\u001b[0m, in \u001b[0;36mupdate_grammar\u001b[0;34m(grammar, home_graph, away_graph, mode, mu)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u, v \u001b[38;5;129;01min\u001b[39;00m tqdm(changes, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madditions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m conquered \u001b[38;5;129;01mand\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m conquered:\n\u001b[0;32m---> 97\u001b[0m         charted_grammar \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_rule_domestic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcharted_grammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m conquered \u001b[38;5;129;01mand\u001b[39;00m v \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m conquered:\n\u001b[1;32m     99\u001b[0m         charted_grammar \u001b[38;5;241m=\u001b[39m update_rule_diplomatic(charted_grammar, u, v, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/repos/temporal_VRG/notebooks/../src/rule_transitions.py:45\u001b[0m, in \u001b[0;36mupdate_rule_domestic\u001b[0;34m(grammar, u, v, mode)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<<mode>> must be either \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     43\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfound mode=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m rule, parent_idx, new_idx \u001b[38;5;241m=\u001b[39m \u001b[43mincorporate_new_rule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_rule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_rule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhich_parent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# parent_idx = grammar.rule_list.index(parent_rule)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# new_idx = grammar.rule_list.index(new_rule)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# grammar.temporal_matrix[parent_idx, parent_idx] = max(0, grammar.temporal_matrix[parent_idx, parent_idx] - 1)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m grammar\u001b[38;5;241m.\u001b[39mtemporal_matrix[parent_idx, new_idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/repos/temporal_VRG/notebooks/../src/rule_transitions.py:102\u001b[0m, in \u001b[0;36mincorporate_new_rule\u001b[0;34m(grammar, parent_rule, new_rule, which_parent, mode)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhash\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m parent_idx, other_rule \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(grammar\u001b[38;5;241m.\u001b[39mrule_list):\n\u001b[0;32m--> 102\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mparent_rule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash_equals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother_rule\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m new_idx, other_rule \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(grammar\u001b[38;5;241m.\u001b[39mrule_list):\n",
      "File \u001b[0;32m~/repos/temporal_VRG/notebooks/../cnrg/Rule.py:47\u001b[0m, in \u001b[0;36mBaseRule.hash_equals\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     44\u001b[0m         d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     46\u001b[0m hash1 \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mweisfeiler_lehman_graph_hash(g1, node_attr\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m hash2 \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweisfeiler_lehman_graph_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hash1 \u001b[38;5;241m==\u001b[39m hash2\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/networkx/algorithms/graph_hashing.py:151\u001b[0m, in \u001b[0;36mweisfeiler_lehman_graph_hash\u001b[0;34m(G, edge_attr, node_attr, iterations, digest_size)\u001b[0m\n\u001b[1;32m    149\u001b[0m subgraph_hash_counts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[0;32m--> 151\u001b[0m     node_labels \u001b[38;5;241m=\u001b[39m \u001b[43mweisfeiler_lehman_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     counter \u001b[38;5;241m=\u001b[39m Counter(node_labels\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# sort the counter, extend total counts\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/networkx/algorithms/graph_hashing.py:143\u001b[0m, in \u001b[0;36mweisfeiler_lehman_graph_hash.<locals>.weisfeiler_lehman_step\u001b[0;34m(G, labels, edge_attr)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39mnodes():\n\u001b[1;32m    142\u001b[0m     label \u001b[38;5;241m=\u001b[39m _neighborhood_aggregate(G, node, labels, edge_attr\u001b[38;5;241m=\u001b[39medge_attr)\n\u001b[0;32m--> 143\u001b[0m     new_labels[node] \u001b[38;5;241m=\u001b[39m \u001b[43m_hash_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdigest_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_labels\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/networkx/algorithms/graph_hashing.py:14\u001b[0m, in \u001b[0;36m_hash_label\u001b[0;34m(label, digest_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_hash_label\u001b[39m(label, digest_size):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mblake2b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mascii\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdigest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdigest_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhexdigest()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataname = 'fb-messages'\n",
    "lookbacks = [0]\n",
    "\n",
    "base_grammars = {lookback: [] for lookback in lookbacks}\n",
    "joint_grammars = {lookback: [] for lookback in lookbacks}\n",
    "indep_grammars = {lookback: [] for lookback in lookbacks}\n",
    "\n",
    "base_mdls = {lookback: [] for lookback in lookbacks}\n",
    "joint_mdls = {lookback: [] for lookback in lookbacks}\n",
    "joint_lls = {lookback: [] for lookback in lookbacks}\n",
    "indep_mdls = {lookback: [] for lookback in lookbacks}\n",
    "indep_lls = {lookback: [] for lookback in lookbacks}\n",
    "\n",
    "mu = 4\n",
    "for lookback in lookbacks:\n",
    "    # loaded = load_data(dataname=dataname, lookback=lookback)\n",
    "    # graphs = [g for _, g in loaded]\n",
    "    graphs, years = read_data(dataname=dataname, lookback=lookback)\n",
    "    \n",
    "    graphs = graphs[0:]\n",
    "    \n",
    "    base_mdl = []\n",
    "    joint_ll = []\n",
    "    joint_mdl = []\n",
    "    indep_ll = []\n",
    "    indep_mdl = []\n",
    "\n",
    "    for idx, (home_graph, away_graph) in enumerate(zip(graphs[:-1], graphs[1:])):\n",
    "        base_grammar = decompose(home_graph, mu=mu)\n",
    "        joint_grammar = update_grammar(base_grammar, home_graph, away_graph, mode='joint')\n",
    "        indep_grammar = update_grammar(base_grammar, home_graph, away_graph, mode='independent')\n",
    "        \n",
    "        base_grammars[lookback] += [base_grammar]\n",
    "        joint_grammars[lookback] += [joint_grammar]\n",
    "        indep_grammars[lookback] += [indep_grammar]\n",
    "        \n",
    "        base_mdl += [base_grammar.calculate_cost()]\n",
    "        \n",
    "        joint_mdl += [joint_grammar.calculate_cost()]\n",
    "        joint_ll += [joint_grammar.conditional_ll()]\n",
    "        \n",
    "        joint_mdls[lookback] += [joint_grammar.calculate_cost()]\n",
    "        joint_lls[lookback] += [joint_grammar.conditional_ll()]\n",
    "        indep_mdls[lookback] += [indep_grammar.calculate_cost()]\n",
    "        indep_lls[lookback] += [indep_grammar.conditional_ll()]\n",
    "    \n",
    "    base_grammar = decompose(graphs[-1], mu=mu)\n",
    "    base_grammars[lookback] += [base_grammar]\n",
    "    base_mdls[lookback] += [base_grammar.calculate_cost()]\n",
    "\n",
    "    with open(f'../results/experiment_sequential/{dataname}_base.grammars', 'wb') as outfile:\n",
    "        pickle.dump(base_grammars, outfile)\n",
    "    with open(f'../results/experiment_sequential/{dataname}_joint.grammars', 'wb') as outfile:\n",
    "        pickle.dump(joint_grammars, outfile)\n",
    "    with open(f'../results/experiment_sequential/{dataname}_indep.grammars', 'wb') as outfile:\n",
    "        pickle.dump(indep_grammars, outfile)\n",
    "\n",
    "    with open(f'../results/experiment_sequential/{dataname}_base.mdls', 'wb') as outfile:\n",
    "        pickle.dump(base_mdls, outfile)\n",
    "    with open(f'../results/experiment_sequential/{dataname}_joint.mdls', 'wb') as outfile:\n",
    "        pickle.dump(joint_mdls, outfile)\n",
    "    with open(f'../results/experiment_sequential/{dataname}_joint.lls', 'wb') as outfile:\n",
    "        pickle.dump(joint_lls, outfile)\n",
    "    with open(f'../results/experiment_sequential/{dataname}_indep.mdls', 'wb') as outfile:\n",
    "        pickle.dump(indep_mdls, outfile)\n",
    "    with open(f'../results/experiment_sequential/{dataname}_indep.lls', 'wb') as outfile:\n",
    "        pickle.dump(indep_lls, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2a7bd4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (2, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (13, 13),\n",
       " (12, 11),\n",
       " (12, 11),\n",
       " (23, 24),\n",
       " (21, 22),\n",
       " (19, 15),\n",
       " (456, 875)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = load_data(dataname='email-dnc', lookback=0)\n",
    "graphs = [g for _, g in loaded]\n",
    "[(len(set(cur.nodes()) & set(nxt.nodes())), len(set(cur.edges()) & set(nxt.edges()))) for cur, nxt in zip(graphs[:-1], graphs[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832848eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(209, 0),\n",
       " (323, 0),\n",
       " (396, 0),\n",
       " (414, 0),\n",
       " (422, 0),\n",
       " (457, 0),\n",
       " (465, 0),\n",
       " (467, 0),\n",
       " (389, 0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs, _ = read_data(dataname='fb-messages', lookback=0)\n",
    "[(len(set(cur.nodes()) & set(nxt.nodes())), len(set(cur.edges()) & set(nxt.edges()))) for cur, nxt in zip(graphs[:-1], graphs[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb50272",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joint_lls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba14fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_lls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e64f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8024c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [t for t, _ in loaded]\n",
    "years = years[0:len(graphs)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfda3c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with plt.style.context(['ipynb', 'use_mathtext', 'colors5-light']):\n",
    "plt.title(f'sequential experiments: {dataname}, lookback {lookback}')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('log likelihood')\n",
    "plt.plot(range(len(years)), joint_lls[1], label='joint model')\n",
    "plt.plot(range(len(years)), indep_lls[1], label='independent model')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.ticklabel_format(style='plain')\n",
    "    #plt.savefig(f'../figures/exp3_{dataname}_{cumulative}.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4e0af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with plt.style.context(['ipynb', 'use_mathtext', 'colors5-light']):\n",
    "plt.title(f'sequential experiments: {dataname}, lookback {lookback}')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('minimal description length')\n",
    "plt.plot(range(len(years)), joint_mdls[1], label='joint model')\n",
    "plt.plot(range(len(years)), indep_mdls[1], label='independent model')\n",
    "plt.plot(range(len(years)), base_mdls[1], label='base model')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.ticklabel_format(style='plain')\n",
    "    #plt.savefig(f'../figures/exp3_{dataname}_{cumulative}.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f7094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a0067e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47a91b33",
   "metadata": {},
   "source": [
    "# accumulated sequential experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfede589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dfb920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
